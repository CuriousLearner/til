[{"path": "python_pathlib-path-expand-user.md", "topic": "python", "title": "Expand home directory paths in `pathlib.Path`", "url": "https://github.com/CuriousLearner/til/blob/main/python/pathlib-path-expand-user.md", "body": "To expand home directory paths in `pathlib.Path`, use the `expanduser()` method. This converts the `~` to the full home directory path.\n\n```python\nfrom pathlib import Path\n\npath = Path(\"~/.private_keys/project-x.2024-06-23.private-key.pem\").expanduser()\n\n# Users/CuriousLearner/.private_keys/project-x.2024-06-23.private-key.pem\n```", "created": "2024-06-23T09:25:31+05:30", "created_utc": "2024-06-23T03:55:31+00:00", "updated": "2024-06-23T09:25:31+05:30", "updated_utc": "2024-06-23T03:55:31+00:00"}, {"path": "python_update_dependencies_in_requirements.md", "topic": "python", "title": "Update dependencies in requirements.txt", "url": "https://github.com/CuriousLearner/til/blob/main/python/update_dependencies_in_requirements.md", "body": "You can use `pur` to update all dependencies in a requirements file like:\n\n```\npur -r requirements.txt\n```\n\n`pur` never modifies your environment or installed packages, it just updates the txt file with latest dependencies. So you can install requirements with `pip install -r requirements.txt`, afterwards.", "created": "2023-11-18T19:30:48+05:30", "created_utc": "2023-11-18T14:00:48+00:00", "updated": "2023-11-18T19:30:48+05:30", "updated_utc": "2023-11-18T14:00:48+00:00"}, {"path": "python_handle_cors_simple_http_server.md", "topic": "python", "title": "Handle CORS in a Simple HTTP Server", "url": "https://github.com/CuriousLearner/til/blob/main/python/handle_cors_simple_http_server.md", "body": "This is a simple HTTP server that serves the current directory and handles CORS by adding the `Access-Control-Allow-Origin` header to the response. This is useful when you are working with frontend applications that need to make requests to a server running on a different domain.\n\n```python\nfrom http.server import SimpleHTTPRequestHandler\nimport socketserver\n\nclass CORSRequestHandler(SimpleHTTPRequestHandler):\n    def end_headers(self):\n        self.send_header('Access-Control-Allow-Origin', '*')\n        super().end_headers()\n\nwith socketserver.TCPServer((\"\", 8000), CORSRequestHandler) as httpd:\n    print(\"Serving at port 8000\")\n    httpd.serve_forever()\n```\n\nSave this script as `server.py` and run it using `python server.py`. This will start a simple HTTP server that serves the current directory and handles CORS by allowing requests from any origin.\n\nYou can access the server at `http://localhost:8000` and make requests from your frontend application without any CORS restrictions.\n\nThis is a quick way to set up a simple HTTP server for development purposes and handle CORS without having to configure a full-fledged web server like Apache or Nginx.\n\n**Note:** This server is not suitable for production use as it lacks security features and is not optimized for performance. It is intended for development purposes only.", "created": "2024-04-19T06:06:08+05:30", "created_utc": "2024-04-19T00:36:08+00:00", "updated": "2024-04-19T06:06:08+05:30", "updated_utc": "2024-04-19T00:36:08+00:00"}, {"path": "react_conditional-rendering.md", "topic": "react", "title": "Not to use && for conditional rendering", "url": "https://github.com/CuriousLearner/til/blob/main/react/conditional-rendering.md", "body": "Most tutorials on React will guide to use a pattern like this:\n\n```javascript\ncondition && <ConditionalComponent>\n```\n\nIf `condition` evaluates to `true`, `<ConditionalComponent>` will be rendered.\nIf `condition` evaluates to `false`, `<ConditionalComponent>` won't be rendered.\n\nWhile this works for majority of scenarios (for conditions that evaluate to `boolean`), it isn't a good practice.\n\nIf a condition evaluates to:\n- `0`, a `0` will be displayed in the UI prior to the rendered `ConditionalComponent`.\n- `undefined`, an exception will happen and UI will break: `\"Uncaught Error: Error(...): Nothing was returned from render. This usually means a return statement is missing. Or, to render nothing, return null.\"`\n\n\n## Best practice\n\nJavascript's ternary operator comes to rescue here. It would prevent the above issues from occuring\n\n```javascript\ncondition ? <ConditionalComponent /> : null\n```", "created": "2023-02-12T02:37:33+05:30", "created_utc": "2023-02-11T21:07:33+00:00", "updated": "2023-02-12T02:37:33+05:30", "updated_utc": "2023-02-11T21:07:33+00:00"}, {"path": "terragrunt_force-unlock-state.md", "topic": "terragrunt", "title": "Force unlock state file", "url": "https://github.com/CuriousLearner/til/blob/main/terragrunt/force-unlock-state.md", "body": "If you're dealing with a locked state in Terragrunt, you can unlock it using the following command:\n\n```bash\nterragrunt force-unlock <LOCK_ID>\n```\n\nThis action should be taken cautiously and only when you're certain that no ongoing `plan` or `apply` operations are running in Terragrunt.", "created": "2024-09-06T09:18:19+05:30", "created_utc": "2024-09-06T03:48:19+00:00", "updated": "2024-09-06T09:18:19+05:30", "updated_utc": "2024-09-06T03:48:19+00:00"}, {"path": "terraform_lifecycle-ignore-changes.md", "topic": "terraform", "title": "Lifecycle Ignore changes", "url": "https://github.com/CuriousLearner/til/blob/main/terraform/lifecycle-ignore-changes.md", "body": "> `lifecycle` is a nested block that can appear within a resource block. The `lifecycle` block and its contents are meta-arguments, available for all resource blocks regardless of type.\n\n> `ignore_changes` (list of attribute names) - By default, Terraform detects any difference in the current settings of a real infrastructure object and plans to update the remote object to match configuration.\n\n\nThis is helpful for example in `aws_ecs_service` resource when you want to avoid any changes in the task definition because the version number of the task definition will be out of terraform's cycle of managing the resource.\n\n```bash\nresource \"aws_ecs_service\" \"example\" {\n  name            = \"example-service\"\n  cluster         = aws_ecs_cluster.example.id\n  task_definition = aws_ecs_task_definition.example.arn\n  desired_count   = 1\n\n  lifecycle {\n    ignore_changes = [\n        task_definition, desired_count\n    ]\n  }\n}\n```\n\nThis also ignore the `desired_count` which is useful when you've autoscaling setup. So, tf doesn't want to be concerned on the number of tasks running.", "created": "2024-07-03T09:01:17+05:30", "created_utc": "2024-07-03T03:31:17+00:00", "updated": "2024-07-03T09:01:17+05:30", "updated_utc": "2024-07-03T03:31:17+00:00"}, {"path": "terraform_zip-lambda-code.md", "topic": "terraform", "title": "Zip Lambda code", "url": "https://github.com/CuriousLearner/til/blob/main/terraform/zip-lambda-code.md", "body": "You can configure terraform to zip-lambda function on triggers like:\n\n```bash\n# Zip the Lambda Function Code (local-exec example)\nresource \"null_resource\" \"zip_lambda\" {\n  provisioner \"local-exec\" {\n    command = \"zip lambda_function.zip lambda_function.py\"\n  }\n\n  triggers = {\n    always_run = \"${timestamp()}\"\n  }\n}\n```", "created": "2024-09-06T09:14:26+05:30", "created_utc": "2024-09-06T03:44:26+00:00", "updated": "2024-09-06T09:14:26+05:30", "updated_utc": "2024-09-06T03:44:26+00:00"}, {"path": "terraform_get_environment_variables.md", "topic": "terraform", "title": "Reading directly from environment variables", "url": "https://github.com/CuriousLearner/til/blob/main/terraform/get_environment_variables.md", "body": "We can use `get_env` function to directly read environment variables present. This means that the variables don't need to have `TF_VAR_` prefix. We are directly reading `TF_STATE_ROLE_ARN` if present in the env, and if not, then using the default value.\n\n\n```tf\nlocals {\n  # This will check the regular environment variable \"TF_CI_ROLE_ARN\"\n  tf_state_role_arn = get_env(\"TF_STATE_ROLE_ARN\", \"arn:aws:iam::XXXXXXXXX:role/terraform-state\")\n}\n\nremote_state {\n  backend = \"s3\"\n\n  config = {\n    bucket         = local.bucket\n    region         = local.region\n    key            = local.key\n    dynamodb_table = local.dynamodb_table\n    encrypt        = true\n    role_arn       = local.tf_state_role_arn\n  }\n}\n```", "created": "2024-09-20T02:06:09+05:30", "created_utc": "2024-09-19T20:36:09+00:00", "updated": "2024-09-20T02:06:09+05:30", "updated_utc": "2024-09-19T20:36:09+00:00"}, {"path": "cli_envsubst-command-for-config-files.md", "topic": "cli", "title": "`envsubst` command for substituting values in config files", "url": "https://github.com/CuriousLearner/til/blob/main/cli/envsubst-command-for-config-files.md", "body": "We can have files that contain variables which are replaced by environment variables at runtime. This is particularly useful for configuration files, where sensitive information like API keys or database passwords should not be hardcoded and checked into version control.\n\n`envsubst` is a command-line utility used for substituting the values of environment variables into strings or files. It's particularly useful for templating configuration files with environment-specific values.\n\n## Example:\n\nSuppose you have a configuration template file `config.template` with the following content:\n\n```bash\napi_url=http://$API_HOST:$API_PORT/api\ndb_url=postgres://$DB_USER:$DB_PASS@$DB_HOST:$DB_PORT/$DB_NAME\n```\n\nDefine env variables:\n\n```bash\nexport API_HOST=api.example.com\nexport API_PORT=8080\nexport DB_USER=myuser\nexport DB_PASS=mypassword\nexport DB_HOST=db.example.com\nexport DB_PORT=5432\nexport DB_NAME=mydatabase\n```\n\nRun `envsubst` to replace the placeholders with the actual values:\n\n```bash\nenvsubst < config.template > config.conf\n```\n\nThis will create a new file `config.conf` with the environment variables replaced.\n\nThe `config.conf` will now look like this:\n\n```bash\napi_url=http://api.example.com:8080/api\ndb_url=postgres://myuser:mypassword@db.example.com:5432/mydatabase\n```", "created": "2024-07-28T05:21:36+05:30", "created_utc": "2024-07-27T23:51:36+00:00", "updated": "2024-07-28T05:21:36+05:30", "updated_utc": "2024-07-27T23:51:36+00:00"}, {"path": "cli_pass-arguments-from-previous-command.md", "topic": "cli", "title": "Pass Arguments From Previous Command", "url": "https://github.com/CuriousLearner/til/blob/main/cli/pass-arguments-from-previous-command.md", "body": "`$_` can be used to pass arguments from previous command\n\nExample:\n\n```\nmkdir hello-go && code $_\n```", "created": "2023-07-19T17:56:42+05:30", "created_utc": "2023-07-19T12:26:42+00:00", "updated": "2023-07-19T17:56:42+05:30", "updated_utc": "2023-07-19T12:26:42+00:00"}, {"path": "cli_execute-previous-command-with-sudo.md", "topic": "cli", "title": "Execute last command with sudo", "url": "https://github.com/CuriousLearner/til/blob/main/cli/execute-previous-command-with-sudo.md", "body": "From the bash manual:\n\n> 9.3.1 Event Designators\n>\n> !! - Refer to the previous command. This is a synonym for \u2018!-1\u2019.\n\nUse `sudo !!` to run last command with uplifted privilege.", "created": "2023-02-13T22:37:47+05:30", "created_utc": "2023-02-13T17:07:47+00:00", "updated": "2023-02-13T22:37:47+05:30", "updated_utc": "2023-02-13T17:07:47+00:00"}, {"path": "vlc_cast-video-to-chromecast.md", "topic": "vlc", "title": "Cast video to chromecast", "url": "https://github.com/CuriousLearner/til/blob/main/vlc/cast-video-to-chromecast.md", "body": "> To cast your videos from your Mac to Chromecast, all you need to do is Open VLC and click `Playback` > `Renderer` from the Apple menu bar. Then select the name of your Chromecast device from the list.", "created": "2023-02-13T22:41:29+05:30", "created_utc": "2023-02-13T17:11:29+00:00", "updated": "2023-02-13T22:41:29+05:30", "updated_utc": "2023-02-13T17:11:29+00:00"}, {"path": "markdown_markdown-alerts.md", "topic": "markdown", "title": "Markdown Alerts", "url": "https://github.com/CuriousLearner/til/blob/main/markdown/markdown-alerts.md", "body": "Markdown alerts are a great way to emphasize important information in your documentation. Different types of alerts can be used to convey different levels of importance and types of information.\n\n## Markdown Alert Types\n\n### Note\n\n```bash\n> [!NOTE]\n> Highlights information that users should take into account, even when skimming.\n```\n\n### Tip\n\n```bash\n> [!TIP]\n> Optional information to help a user be more successful.\n```\n\n### Important\n\n```bash\n> [!IMPORTANT]\n> Crucial information necessary for users to succeed.\n```\n\n### Warning\n\n```bash\n> [!WARNING]\n> Critical content demanding immediate user attention due to potential risks.\n```\n\n### Caution\n\n```bash\n> [!CAUTION]\n> Negative potential consequences of an action.\n```\n\n## Example Usage\n\nHere\u2019s how you can use these alerts in a markdown document:\n\n### Note Example\n\n> [!NOTE]\n> Make sure to update your dependencies regularly to avoid security vulnerabilities.\n\n### Tip Example\n\n> [!TIP]\n> Use `envsubst` to easily substitute environment variables in your configuration files.\n\n### Important Example\n\n> [!IMPORTANT]\n> Always back up your data before performing major updates or changes.\n\n### Warning Example\n\n> [!WARNING]\n> Running this script will delete all files in the specified directory. Proceed with caution!\n\n### Caution Example\n\n> [!CAUTION]\n> Changing the configuration file might cause the application to become unstable if not done correctly.", "created": "2024-07-28T05:31:11+05:30", "created_utc": "2024-07-28T00:01:11+00:00", "updated": "2024-07-28T05:31:11+05:30", "updated_utc": "2024-07-28T00:01:11+00:00"}, {"path": "pytest_run_filtered_tests_by_substring.md", "topic": "pytest", "title": "Run tests that match substring in their name", "url": "https://github.com/CuriousLearner/til/blob/main/pytest/run_filtered_tests_by_substring.md", "body": "You can filter and run only tests that contain or do not contain some substring in their name.\n\nExamples:\n\n```bash\n# run all tests that contain `auth` in their name\n$ pytest -k auth\n\n# run all tests that do not contain `auth` in their name\n$ pytest -k 'not auth'\n```", "created": "2024-04-03T07:36:31+05:30", "created_utc": "2024-04-03T02:06:31+00:00", "updated": "2024-04-03T07:36:31+05:30", "updated_utc": "2024-04-03T02:06:31+00:00"}, {"path": "pytest_fixture_autouse.md", "topic": "pytest", "title": "Autouse fixtures for common test dependencies", "url": "https://github.com/CuriousLearner/til/blob/main/pytest/fixture_autouse.md", "body": "Fixtures can be marked as autouse, meaning they will be invoked for all tests in a module without a direct dependency on them. This can be useful for setting up common test dependencies, such as a temporary directory or a database connection.\n\n```python\nimport pytest\n\n@pytest.fixture(autouse=True)\ndef setup_database():\n    print(\"\\nSetup database\")\n    yield\n    print(\"\\nTeardown database\")\n\ndef test_insert_data():\n    print(\"Inserting data\")\n\ndef test_delete_data():\n    print(\"Deleting data\")\n```\n\nWhen running the tests, the output will be:\n\n```shell\nSetup database\nInserting data\nTeardown database\nSetup database\nDeleting data\nTeardown database\n```\n\nIn the above example, the `setup_database` fixture is marked as autouse, so it will be invoked for all tests in the module. The fixture sets up the database before each test and tears it down after each test.", "created": "2024-03-28T06:28:09+05:30", "created_utc": "2024-03-28T00:58:09+00:00", "updated": "2024-03-28T06:28:09+05:30", "updated_utc": "2024-03-28T00:58:09+00:00"}, {"path": "aws_acm-cloudfront.md", "topic": "aws", "title": "ACM certificate should always be in us-east-1 for Cloudfront", "url": "https://github.com/CuriousLearner/til/blob/main/aws/acm-cloudfront.md", "body": "Since cloudfront is a global service, the certificate attached to it should always be in `us-east-1`.\n\nFor other services, that are regional, like Layer 7 - ALBs (Application Load Balancers), the region of SSL certificate depends on the region where ALB is placed.", "created": "2023-02-12T03:11:52+05:30", "created_utc": "2023-02-11T21:41:52+00:00", "updated": "2023-02-12T03:11:52+05:30", "updated_utc": "2023-02-11T21:41:52+00:00"}, {"path": "aws_reserving-five-ips-per-subnet.md", "topic": "aws", "title": "AWS reserves five IPs per subnet", "url": "https://github.com/CuriousLearner/til/blob/main/aws/reserving-five-ips-per-subnet.md", "body": "Each subnet in AWS has 5 IP address registered. The following IP Address are registered as follows, (depending on the last octet or) ending with:\n\n- `.0` - Network Address\n- `.1` - VPC router\n- `.2` - DNS\n- `.3` - Reserved\n- `.255` - Broadcast Address", "created": "2023-02-12T03:25:56+05:30", "created_utc": "2023-02-11T21:55:56+00:00", "updated": "2023-02-12T03:25:56+05:30", "updated_utc": "2023-02-11T21:55:56+00:00"}, {"path": "aws_no-self-signed-certificate-cloudfront.md", "topic": "aws", "title": "No self-signed certificates in Cloudfront's SSL connection", "url": "https://github.com/CuriousLearner/til/blob/main/aws/no-self-signed-certificate-cloudfront.md", "body": "If using cloudfront, then there will always be 2 SSL connections namely\n`Visitor => Cloudfront` and then `Cloudfront => origin`. Both of these will be publically signed certificate. You can never use self-signed certificate.", "created": "2023-02-12T03:13:44+05:30", "created_utc": "2023-02-11T21:43:44+00:00", "updated": "2023-02-12T03:13:44+05:30", "updated_utc": "2023-02-11T21:43:44+00:00"}, {"path": "docker_filter_list_of_containers.md", "topic": "docker", "title": "Filter list of docker containers", "url": "https://github.com/CuriousLearner/til/blob/main/docker/filter_list_of_containers.md", "body": "`docker ps` commands offer `-q` stands for `quiet`, that only displays container ids.\n\nThe `-f` flag is for filtering the list of running containers based on conditions provided.\n\nFor example:\n\n```\ndocker ps -qf \"name=django-web\"\n```\n\nwill list down the container id for container with name as `django-web`.\n\nYou may plug it into commands like:\n\n```\ndocker exec -it $(docker ps -qf \"name=django-web\") python manage.py migrate\n```\n\nto run the migrations from the django container.", "created": "2023-11-20T17:57:01+05:30", "created_utc": "2023-11-20T12:27:01+00:00", "updated": "2023-11-20T17:57:01+05:30", "updated_utc": "2023-11-20T12:27:01+00:00"}, {"path": "docker_get-rid-of-persistent-volume-docker-compose.md", "topic": "docker", "title": "Get rid of persistent volumes in `docker compose down`", "url": "https://github.com/CuriousLearner/til/blob/main/docker/get-rid-of-persistent-volume-docker-compose.md", "body": "```sh\ndocker compose down -v db\n```\n\n`docker-compose down`: This command stops and removes the containers, networks, volumes, and other resources created by `docker-compose up`. It is a convenient way to clean up resources after running Docker Compose services.\n\n`-v db`: The `-v` option instructs Docker Compose to remove the volume associated with the specified service (`db` in this case). This ensures that not only containers but also any persistent data stored in the volume is deleted. Useful when you want to clean up the entire database service, including its associated data volume, without affecting other services defined in the `docker-compose.yml`.", "created": "2024-06-23T09:47:51+05:30", "created_utc": "2024-06-23T04:17:51+00:00", "updated": "2024-06-23T09:47:51+05:30", "updated_utc": "2024-06-23T04:17:51+00:00"}, {"path": "docker_target-in-docker-compose.md", "topic": "docker", "title": "Target in Docker Compose File", "url": "https://github.com/CuriousLearner/til/blob/main/docker/target-in-docker-compose.md", "body": "By associating specific stages with targets, you can build only the necessary components, reducing build times and optimizing resource usage.\n\nIf you have a Dockerfile, you can specify a target to build specific stages, like this:\n\n```docker\n# Stage 1: Build stage\nFROM python:3.7-slim as builder\n\nWORKDIR /app\n\nCOPY requirements.txt /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Stage 2: Runtime stage\nFROM python:3.7-slim as runtime\n\nWORKDIR /app\n\nCOPY --from=builder /usr/local/lib/python3.7/site-packages /usr/local/lib/python3.7/site-packages\nCOPY --from=builder /app /app\n\nCMD [\"python\", \"manage.py\", \"runserver\"]\n```\n\nThis Dockerfile separates the build process (`builder` stage) from the runtime environment (`runtime` stage), optimizing the final image size and dependencies.\n\nTo build and deploy only the runtime environment, define a target in your Docker Compose file:\n\n```yaml\nversion: '3'\n\nservices:\n  web:\n    build:\n      context: .\n      target: runtime\n```\n\nYou can then build your image with a specific target using Docker Compose:\n\n```bash\ndocker-compose build web\n```\n\nOr directly with docker build:\n\n```bash\ndocker build -t my_image . --target runtime\n```\n\nThis approach ensures you build only the necessary stages, improving efficiency.", "created": "2024-07-28T05:06:53+05:30", "created_utc": "2024-07-27T23:36:53+00:00", "updated": "2024-07-28T05:06:53+05:30", "updated_utc": "2024-07-27T23:36:53+00:00"}, {"path": "git_diff-name-only.md", "topic": "git", "title": "`git diff --name-only` for file names only", "url": "https://github.com/CuriousLearner/til/blob/main/git/diff-name-only.md", "body": "`git diff --name-only` is a command used in Git, a distributed version control system. This command compares the working directory with the staging area (index) and outputs the names of files that have changed.\n\nThe `--name-only` flag is used to show only the names of the files that have changed, without any additional information. This can be useful when you want to see a list of files that have been modified, added, or deleted.\n\nHere is an example of how to use `git diff --name-only`:\n\n```bash\ngit diff --name-only\n```\n\nThis will output a list of file names that have changed between the working directory and the staging area.\n\nAlternate usage:\n\n```bash\ngit diff --name-only HEAD~1 HEAD\n```\n\nThis will output a list of file names that have changed between the current commit and the previous commit.\n\n```bash\ngit diff --name-only <commit1> <commit2>\n```\n\nor\n\n```bash\ngit diff --name-only <branch1> <branch2>\n```", "created": "2024-04-18T08:09:42+05:30", "created_utc": "2024-04-18T02:39:42+00:00", "updated": "2024-04-18T08:17:41+05:30", "updated_utc": "2024-04-18T02:47:41+00:00"}, {"path": "git_ignore-commits-in-git-blame.md", "topic": "git", "title": "Ignore commits in git-blame view", "url": "https://github.com/CuriousLearner/til/blob/main/git/ignore-commits-in-git-blame.md", "body": "> All revisions specified in the .git-blame-ignore-revs file, which must be in the root directory of your repository, are hidden from the blame view using Git's `git blame --ignore-revs-file` configuration setting.\n\nThe file can look like this, preferrably should always have comments:\n\n```bash\n# .git-blame-ignore-revs\n# Removed semi-colons from the entire codebase\na8940f7fbddf7fad9d7d50014d4e8d46baf30592\n# Converted all JavaScript to TypeScript\n69d029cec8337c616552756310748c4a507bd75a\n```\n\nOptionally, specify path for this ignore-revs-file, like:\n\n```bash\ngit blame --ignore-revs-file .git-blame-ignore-revs\n```\n\nYou can also configure your local git so it always ignores the revs in that file:\n\n```bash\ngit config blame.ignoreRevsFile .git-blame-ignore-revs\n```", "created": "2023-02-13T04:00:02+05:30", "created_utc": "2023-02-12T22:30:02+00:00", "updated": "2023-02-13T04:00:02+05:30", "updated_utc": "2023-02-12T22:30:02+00:00"}, {"path": "git_revert-files-to-state-in-diff-branch.md", "topic": "git", "title": "Revert file(s) state to one in diff branch", "url": "https://github.com/CuriousLearner/til/blob/main/git/revert-files-to-state-in-diff-branch.md", "body": "Often times, we come across a situation where we have made changes in our current branch and want to revert some files to the exact state they were in at a certain point in another branch (diff branch). This can be done using `git`'s powerful features.\n\n```bash\ngit checkout <other-branch> -- <file-or-glob>...\n```\n\nTo check for changes before a checkout, you can use:\n\n```bash\ngit diff <commit-in-diff-branch> <file-or-glob>\n```\n\nExamples:\n\n```bash\n# Check 'README.md' diff from it's state in the master branch.\ngit diff master -- README.md\ngit checkout master -- README.md\n\n# Revert 'README.md' to the state it was in branch 'feature-branch'\ngit checkout feature-branch -- README.md\n```", "created": "2024-07-28T05:14:15+05:30", "created_utc": "2024-07-27T23:44:15+00:00", "updated": "2024-07-28T05:14:15+05:30", "updated_utc": "2024-07-27T23:44:15+00:00"}, {"path": "git_merge-base-for-common-ancestor-commit.md", "topic": "git", "title": "`git merge-base` for common-ancestor commit", "url": "https://github.com/CuriousLearner/til/blob/main/git/merge-base-for-common-ancestor-commit.md", "body": "`git merge-base` is a command used in Git, a distributed version control system. This command finds the (most recent) common ancestor commit of two branches or commits.\n\nThe command is typically used in the format: `git merge-base <commit1> <commit2>` or `git merge-base <branch1> <branch2>`. This will output the SHA-1 hash of the common ancestor commit.\n\nFor example, if you have two branches, master and feature, and you want to find the commit where the feature branch diverged from master, you would use:\n\n```bash\ngit merge-base master feature\n```\n\nThis command is particularly useful when you want to see what has changed between two branches since they diverged. You can use the output of `git merge-base` as the argument to `git diff` to see these changes.\n\nRemember, `git merge-base` only shows the most recent common ancestor. If there are multiple common ancestors, it does not display them all.", "created": "2024-04-18T08:06:10+05:30", "created_utc": "2024-04-18T02:36:10+00:00", "updated": "2024-04-18T08:17:41+05:30", "updated_utc": "2024-04-18T02:47:41+00:00"}, {"path": "git_rev-parse-for-revision-information.md", "topic": "git", "title": "`git rev-parse` for parsing Git revision information", "url": "https://github.com/CuriousLearner/til/blob/main/git/rev-parse-for-revision-information.md", "body": "`git rev-parse` is a command used in Git, a distributed version control system. This command is used to parse Git revision information. It can be used to get the SHA-1 hash of a commit, the name of a branch, or the path of a file in the repository.\n\nHere are some examples of how to use `git rev-parse`:\n\n1. Get the SHA-1 hash of the current commit:\n\n   ```bash\n   git rev-parse HEAD\n   ```\n\n    This will output the SHA-1 hash of the current commit.\n\n2. Get the name of the current branch:\n\n    ```bash\n    git rev-parse --abbrev-ref HEAD\n    ```\n\n    This will output the name of the current branch.", "created": "2024-04-18T08:16:11+05:30", "created_utc": "2024-04-18T02:46:11+00:00", "updated": "2024-04-18T08:17:41+05:30", "updated_utc": "2024-04-18T02:47:41+00:00"}, {"path": "poetry_clear-cache-for-resolving-dependencies-faster.md", "topic": "poetry", "title": "Clear cache for resolving dependencies faster", "url": "https://github.com/CuriousLearner/til/blob/main/poetry/clear-cache-for-resolving-dependencies-faster.md", "body": "Well, I know caches are there for faster access. Unfortunately, poetry has a bug that is likely related to clearing out partial/incomplete/corrupted by concurrent usage downloads that can cause an indefinite hang while resolving dependencies.\n\nIf we clear the cache, it would be able to resolve dependencies faster.\n\nUse the following command for clearing the cache:\n\n```\npoetry cache clear --all pypi\n```\n\nMore [information on Github issue here](https://github.com/python-poetry/poetry/issues/2094#issuecomment-1248526469)", "created": "2023-02-16T18:18:33+05:30", "created_utc": "2023-02-16T12:48:33+00:00", "updated": "2023-02-16T18:20:32+05:30", "updated_utc": "2023-02-16T12:50:32+00:00"}, {"path": "poetry_editable_installation_for_package.md", "topic": "poetry", "title": "Editable installation for a package", "url": "https://github.com/CuriousLearner/til/blob/main/poetry/editable_installation_for_package.md", "body": "Just learned about editable installation in Python! It's a way to install a package in 'editable' mode, which means you can make changes to the package and see the changes reflected immediately without reinstalling it. \ud83d\ude80\n\n```bash\npip install -e .\n```\n\nIn poetry, you can use the `path` option with `develop` as `true` to install a package in editable mode. This is useful when you want to develop a package and see the changes reflected immediately without reinstalling it.\n\n```bash\npacakge = {path= \"/path/to/package\", develop = true}\n```\n\nWith poetry, you can also use the `--editable` flag to install a package in editable mode.\n\n```bash\npoetry add --editable /path/to/package\n```", "created": "2024-04-03T07:46:55+05:30", "created_utc": "2024-04-03T02:16:55+00:00", "updated": "2024-04-03T08:53:39+05:30", "updated_utc": "2024-04-03T03:23:39+00:00"}, {"path": "poetry_generate_requirements_without_hashes.md", "topic": "poetry", "title": "Generate requirements without hashes", "url": "https://github.com/CuriousLearner/til/blob/main/poetry/generate_requirements_without_hashes.md", "body": "When using Docker, you can export dependencies to a `requirements.txt` file without hashes to decrease time to resolve dependencies.\n\n```bash\npoetry export --without-hashes --format=requirements.txt > requirements.txt\n```", "created": "2024-04-03T07:33:45+05:30", "created_utc": "2024-04-03T02:03:45+00:00", "updated": "2024-04-03T07:33:45+05:30", "updated_utc": "2024-04-03T02:03:45+00:00"}, {"path": "psql_restore-via-template.md", "topic": "psql", "title": "Restore database via template", "url": "https://github.com/CuriousLearner/til/blob/main/psql/restore-via-template.md", "body": "To restore a PostgreSQL database using a template, you can use the `createdb` command with the `--template` option. This method is faster than traditional backup and restore because it copies the database files directly, avoiding the overhead of SQL-based operations.\n\nFor PostgreSQL 15, the createdb command uses the `WAL_LOG` method by default. This method copies the database block by block and logs each block in the write-ahead log. It's the most efficient strategy for small template databases.\n\nThe older `FILE_COPY` method writes a small record to the write-ahead log for each tablespace, representing a directory copy at the filesystem level.\n\nExample:\n\nTo create a new database `newdb` from the template `templatedb`:\n\n```bash\ncreatedb newdb --template=templatedb\n```\n\nThis command efficiently copies the schema and data from `templatedb` to `newdb`.\n\nWith create database command,\n\n```sql\ncreate database newdb template templatedb;\n```", "created": "2024-06-23T09:43:20+05:30", "created_utc": "2024-06-23T04:13:20+00:00", "updated": "2024-06-23T09:43:20+05:30", "updated_utc": "2024-06-23T04:13:20+00:00"}, {"path": "psql_dump-and-restore.md", "topic": "psql", "title": "Dump and Restore database", "url": "https://github.com/CuriousLearner/til/blob/main/psql/dump-and-restore.md", "body": "To dump:\n\n```\nPGPASSWORD=<password> pg_dump --username <username> <dbname> > dump.sql\n```\n\nTo restore:\n\n```\nPGPASSWORD=<password> psql --username <username> <dbname> -p <port> -h <host> < dump.sql\n```", "created": "2023-07-08T01:00:47+05:30", "created_utc": "2023-07-07T19:30:47+00:00", "updated": "2023-07-08T01:00:47+05:30", "updated_utc": "2023-07-07T19:30:47+00:00"}, {"path": "npm_clean_install_for_ci_pipelines.md", "topic": "npm", "title": "`npm ci` (clean install) for CI pipelines", "url": "https://github.com/CuriousLearner/til/blob/main/npm/clean_install_for_ci_pipelines.md", "body": "Just learned about `npm ci` command! It stands for 'clean install' and is super useful for Continuous Integration setups. Unlike `npm install`, it skips the dependency resolution step by using the existing `package-lock.json` or `npm-shrinkwrap.json`. This ensures faster, consistent builds with exact dependencies. \ud83d\ude80\n\n```bash\nnpm ci\n```", "created": "2024-04-03T07:42:40+05:30", "created_utc": "2024-04-03T02:12:40+00:00", "updated": "2024-04-03T07:42:40+05:30", "updated_utc": "2024-04-03T02:12:40+00:00"}, {"path": "github_show-git-blame-for-a-file.md", "topic": "github", "title": "See git-blame for a file", "url": "https://github.com/CuriousLearner/til/blob/main/github/show-git-blame-for-a-file.md", "body": "While browsing the file on GitHub, if you press `b`, it will open up git-blame of that file, where you can see all changes in the file by everyone.", "created": "2023-02-13T03:47:46+05:30", "created_utc": "2023-02-12T22:17:46+00:00", "updated": "2023-02-13T03:47:46+05:30", "updated_utc": "2023-02-12T22:17:46+00:00"}, {"path": "vim_text-objects-to-make-efficient-changes.md", "topic": "vim", "title": "Use text objects to make efficient changes", "url": "https://github.com/CuriousLearner/til/blob/main/vim/text-objects-to-make-efficient-changes.md", "body": "If you want to change something enclosed within brackets, curly braces, quotes, you can use:\n\n- `ci(` \u2013 **C**hange **I**nside brackets\n for changing\n\n```python\nmy_func(something)\n```\n\nto\n\n```python\nmy_func(something_else)\n```\n\n- `da\u201d` \u2013 **D**elete **A**round double quotes\n\n```python\nprint(\"Hello, World!\")\n```\n\nto\n\n```python\nprint()\n```\n\n- `di]` \u2013 **D**elete **I**nside square brackets\n\n```python\nmy_list = [1, 2, 3]\n```\n\nto\n\n```python\nmy_list = []\n```\n\n- `ci{` \u2013 **C**hange **I**nside curly braces\n\n```python\nmy_dict = {\"key\": \"value\"}\n```\n\nto\n\n```python\nmy_dict = {\"key\": \"new_value\"}\n```\n\n\n- `dap` \u2013 **D**elete **A**round **P**aragraph\n\n```python\ndef my_func():\n    print(\"Hello, World!\")\n```\n\nto\n\n```python\n```\n\n- `ciw` \u2013 **C**hange **I**nside **W**ord\n\n```python\nmy_var = \"value\"\n```\n\nto\n\n```python\nmy_var = \"new_value\"\n```\n\n\n\n- `vaw` \u2013 **V**isually select **A**round **W**ord\n\n```python\nmy_var = \"value\"\n```\n\nto\n\n```python\nmy_var = \"new_value\"\n```", "created": "2023-02-13T03:00:36+05:30", "created_utc": "2023-02-12T21:30:36+00:00", "updated": "2024-04-19T05:58:11+05:30", "updated_utc": "2024-04-19T00:28:11+00:00"}, {"path": "vim_indent-deindent-line.md", "topic": "vim", "title": "Indent and De-indent lines in Vim.", "url": "https://github.com/CuriousLearner/til/blob/main/vim/indent-deindent-line.md", "body": "This is very useful while dealing with Python code, or better yet, editing YAML config files for Kubernetes.\n\nPlace cursor at the start of line, press `Ctrl+v` to visually select and then press `j` to cover as many lines as you want to indent/de-indent.\n\nThen use `>` for indent and `<` for de-indent.\n\nIn insert mode, you can use `Ctrl+t` to indent and `Ctrl+d` to de-indent.", "created": "2023-02-13T03:40:39+05:30", "created_utc": "2023-02-12T22:10:39+00:00", "updated": "2023-02-13T03:40:39+05:30", "updated_utc": "2023-02-12T22:10:39+00:00"}, {"path": "vim_open-file-on-line.md", "topic": "vim", "title": "Open a file on a particular line", "url": "https://github.com/CuriousLearner/til/blob/main/vim/open-file-on-line.md", "body": "Use `vim <filename> +lineno` to open file on that line.\n\nFor example, `vim .env +33` will open `.env` file and place the cursor on line 33.", "created": "2023-02-13T03:54:14+05:30", "created_utc": "2023-02-12T22:24:14+00:00", "updated": "2023-02-13T03:54:14+05:30", "updated_utc": "2023-02-12T22:24:14+00:00"}, {"path": "vim_open-file-on-pattern.md", "topic": "vim", "title": "Open file on a particular pattern in file", "url": "https://github.com/CuriousLearner/til/blob/main/vim/open-file-on-pattern.md", "body": "Open a file directly to a pattern in Vim:\n\n`vim some_file.name +/your_pattern`\n\nlike:\n\n`vim .env +/DEBUG=`\n\nwill open `.env` file exactly on line where `DEBUG=` is mentioned.\n\nWhy? The pattern in your terminal history allows repetition. Useful for `.env` or `config` files.", "created": "2023-02-13T03:31:09+05:30", "created_utc": "2023-02-12T22:01:09+00:00", "updated": "2023-02-13T03:31:09+05:30", "updated_utc": "2023-02-12T22:01:09+00:00"}, {"path": "vim_remove-lines-matching-pattern.md", "topic": "vim", "title": "Remove lines matching a pattern", "url": "https://github.com/CuriousLearner/til/blob/main/vim/remove-lines-matching-pattern.md", "body": "You can use `grep -v`, but let's do this in vim with Vim\u2019s powerful \"global\" command, `:g` for short as:\n\n- `:g/pattern/d` \u2013 Remove lines matching pattern\n- `:g!/pattern/d` \u2013 Remove lines that **do NOT** match the pattern\n- `:v/pattern/d` \u2013 Also removes lines that **do NOT** match the pattern", "created": "2023-02-13T02:48:35+05:30", "created_utc": "2023-02-12T21:18:35+00:00", "updated": "2023-02-13T02:48:35+05:30", "updated_utc": "2023-02-12T21:18:35+00:00"}, {"path": "django_extensions_print-sql-on-orm-queries.md", "topic": "django_extensions", "title": "Print SQL on ORM queries", "url": "https://github.com/CuriousLearner/til/blob/main/django_extensions/print-sql-on-orm-queries.md", "body": "One way to know what SQL queries are being run on executing an ORM statement is with the following:\n\n```\nfrom django.db import connection\n\nconnection.queries\n```\n\nDjango Extensions makes it easy to print all SQL queries if you pass an extra parameter while running shell like:\n\n```\npython manage.py shell_plus --print-sql\n```", "created": "2023-02-16T20:47:57+05:30", "created_utc": "2023-02-16T15:17:57+00:00", "updated": "2023-02-16T20:47:57+05:30", "updated_utc": "2023-02-16T15:17:57+00:00"}, {"path": "wagtail_many-to-many-relationship.md", "topic": "wagtail", "title": "Many to Many relationship in Wagtail", "url": "https://github.com/CuriousLearner/til/blob/main/wagtail/many-to-many-relationship.md", "body": "A Many-to-Many relationship can be implemented using a `ParentalManyToManyField` in Wagtail. This field is designed for use within a `PageModel` and allows you to create a many-to-many relationship between different pages. The `ParentalManyToManyField` allows the relations between m2m linked objects to be stored in memory without writing to the database.\n\n```python\nfrom modelcluster.fields import ParentalManyToManyField\n```\n\nYou can then define the `ParentalManyToManyField` in your Wagtail model, specifying the related page model that you want to establish the many-to-many relationship with.\n\n**Caveat**: If you're using snippets, make sure the snippet is using the `ParentalManyToManyField`, otherwise it won't render correctly with `FieldPanel`. Furthermore, the snippet cannot inherit from `models.Model`, otherwise the m2m relationship will not be saved. They should inherit from `modelcluster.models.ClusterableModel` instead.\n\n```python\nfrom modelcluster.fields import ParentalManyToManyField\nfrom modelcluster.models import ClusterableModel\n\nfrom wagtail.models import Page\nfrom wagtail.snippets.models import register_snippet\n\n\n@register_snippet\nclass MySnippet(ClusterableModel):\n    my_pages = ParentalManyToManyField(Page, related_name=\"+\")\n```\n\nThis will create a many-to-many relationship between the `MySnippet` model and the `Page` model.", "created": "2024-04-25T00:46:51+05:30", "created_utc": "2024-04-24T19:16:51+00:00", "updated": "2024-04-25T00:46:51+05:30", "updated_utc": "2024-04-24T19:16:51+00:00"}, {"path": "wagtail_get-blocks-in-streamblock.md", "topic": "wagtail", "title": "Get blocks in StreamBlock using `blocks_by_name` & `first_block_by_name`", "url": "https://github.com/CuriousLearner/til/blob/main/wagtail/get-blocks-in-streamblock.md", "body": "If you're using a StreamField, you can access the blocks using the `blocks_by_name` method. This will return a list of the blocks with the given name.\n\nExample:\n\n```python\n@register_snippet\nclass Menu(models.Model):\n\n    content = StreamField(\n        [\n            (\"column\", ContentColumnBlock()),\n            (\"sidebar\", SidebarBlock()),\n        ]\n    )\n    def clean(self):\n        super().clean()\n        if len(self.content.blocks_by_name(\"sidebar\")) > 1:\n            raise ValidationError(\"Only one sidebar block is allowed.\")\n        for column_block in self.content.blocks_by_name(\"column\"):\n            if len(column_block.value[\"column\"]) > 3:\n                raise ValidationError(\n                    \"Only up to three choices in each column is allowed.\"\n                )\n```\n\nYou can also use the `first_block_by_name` method if you only want to get the first block with the given name.\n\nExample:\n\n```python\n{{ menu.content.blocks.first_block_by_name(\"column\") }}\n```\n\nThese methods can also be used in templates to access the blocks.", "created": "2024-04-25T00:48:36+05:30", "created_utc": "2024-04-24T19:18:36+00:00", "updated": "2024-04-25T00:51:11+05:30", "updated_utc": "2024-04-24T19:21:11+00:00"}, {"path": "wagtail_lazily_refer_snippet.md", "topic": "wagtail", "title": "Lazily Refer Snippet in blocks", "url": "https://github.com/CuriousLearner/til/blob/main/wagtail/lazily_refer_snippet.md", "body": "`SnippetChooserBlock` in Django Wagtail can cleverly sidestep circular dependencies. By lazily referring to a snippet, you can effectively dodge those pesky circular dependencies that can otherwise tangle up your code. Just set up your `SnippetChooserBlock` like this:\n\n```python\nfrom wagtail.snippets.blocks import SnippetChooserBlock\n\nSnippetChooserBlock(target_model=\"app.ContentSnippet\")\n```\n\nAnd watch as your code becomes cleaner and more maintainable! No more headaches trying to unravel circular dependencies.", "created": "2024-03-30T08:20:08+05:30", "created_utc": "2024-03-30T02:50:08+00:00", "updated": "2024-03-30T08:21:51+05:30", "updated_utc": "2024-03-30T02:51:51+00:00"}, {"path": "pdf_compress-pdf.md", "topic": "pdf", "title": "Reduce file size of PDF files", "url": "https://github.com/CuriousLearner/til/blob/main/pdf/compress-pdf.md", "body": "This would require `gs` to be installed.\n\n```\ncompresspdf() {\n    echo 'Usage: compresspdf [input file] [output file] [screen|ebook|printer|prepress]'\n    gs -sDEVICE=pdfwrite -dNOPAUSE -dQUIET -dBATCH -dPDFSETTINGS=/${3:-\"screen\"} -dCompatibilityLevel=1.4 -sOutputFile=\"$2\" \"$1\"\n}\n```\n\nand then do:\n\n```\ncompresspdf uncompressed-file.pdf compressed-file.pdf screen\n```", "created": "2023-03-15T04:02:40+05:30", "created_utc": "2023-03-14T22:32:40+00:00", "updated": "2023-03-15T04:02:40+05:30", "updated_utc": "2023-03-14T22:32:40+00:00"}, {"path": "pdf_remove-pdf-password.md", "topic": "pdf", "title": "Remove PDF Password", "url": "https://github.com/CuriousLearner/til/blob/main/pdf/remove-pdf-password.md", "body": "Install `qpdf` via brew like:\n\n```\nbrew install qpdf\n```\n\nand then run:\n\n```\nqpdf --decrypt --password=xxxxx encrypted-filename.pdf decrypted-filename.pdf\n```", "created": "2023-03-15T04:02:40+05:30", "created_utc": "2023-03-14T22:32:40+00:00", "updated": "2023-03-15T04:02:40+05:30", "updated_utc": "2023-03-14T22:32:40+00:00"}, {"path": "mastodon_send-direct-message.md", "topic": "mastodon", "title": "Sending direct message on Mastodon", "url": "https://github.com/CuriousLearner/til/blob/main/mastodon/send-direct-message.md", "body": "There are couple of ways to do this.\n\n1. Go on the profile of person who you want to send DM the DM to.  Click on ellipsis, and select `Direct message @<username>`. This would adjust the post visibility to automatically restrict to the person you're sending message. You can start posting as you want.\n\nIn the notifications, you'll see this post with `@` symbol indicating private message.\n\n2. The other way is to adjust your post settings on your own to `Mentioned people only`, and then start posting.`", "created": "2023-02-14T23:00:04+05:30", "created_utc": "2023-02-14T17:30:04+00:00", "updated": "2023-02-14T23:00:04+05:30", "updated_utc": "2023-02-14T17:30:04+00:00"}, {"path": "css_select-by-attr-in-list-of-values.md", "topic": "css", "title": "Select by attr in list of values", "url": "https://github.com/CuriousLearner/til/blob/main/css/select-by-attr-in-list-of-values.md", "body": "You can select an element in the DOM having an attribute with list of values.\n\nBy using the `[attr~='foo']` selector, it only select elements where the attribute contains the string \"foo\", and also takes into consideration that the element should contain an attr value in a space separated list.\n\nExample:\n\n```html\n<div attr='en-us foo bar' />\n```\n\ncan be selected with\n\n```css\n[attr~='foo'] { font-size:smaller; }\n```\n\nIf you want to select value with dash separated, you may do:\n\n```css\n/* value in a dash-separated list, e.g., \"-\" (U+002D) */\n[attr|='en'] { font-size:smaller; }\n```", "created": "2024-04-22T10:42:58+05:30", "created_utc": "2024-04-22T05:12:58+00:00", "updated": "2024-04-22T10:42:58+05:30", "updated_utc": "2024-04-22T05:12:58+00:00"}, {"path": "ssh_setup-ssh-tunneling.md", "topic": "ssh", "title": "Setup SSH Tunneling", "url": "https://github.com/CuriousLearner/til/blob/main/ssh/setup-ssh-tunneling.md", "body": "One plausible use case is accessing database in private subnet by creating SSH tunnel through the EC2 in public subnet like:\n\n```\nssh -L <local-port>:<database>.us-east-2.rds.amazonaws.com:<dbport> ec2-user@<host-ip>\n```\n\nNow you can access the DB on `local-port` in your system.", "created": "2023-07-08T01:17:46+05:30", "created_utc": "2023-07-07T19:47:46+00:00", "updated": "2023-07-08T01:17:46+05:30", "updated_utc": "2023-07-07T19:47:46+00:00"}, {"path": "go_build-tags.md", "topic": "go", "title": "Build tags in Golang", "url": "https://github.com/CuriousLearner/til/blob/main/go/build-tags.md", "body": "A build tag is a line comment starting with // +build\n  and can be executed by `go build -tags=\"foo bar\"` command.\n  Build tags are placed before the package clause near or at the top of the file\n  followed by a blank line or other line comments.\n\nExample:\n\n```go\n// +build windows,!linux\npackage main\n...\n```\n\nIn this example, // +build windows,!linux is used to specify that this code should only be built on Windows and not on Linux.\n\nYou can also use multiple build tags by separating them with a comma.\n\nExample:\n\n```go\n// +build prod, dev, test\npackage main\n...\n```\n\nIn the above example, the code will be built only when running the command with either \"prod\" or \"dev\" or \"test\" as an argument.\n\n```bash\ngo build -tags=\"prod\"\n```", "created": "2024-06-23T09:04:03+05:30", "created_utc": "2024-06-23T03:34:03+00:00", "updated": "2024-06-23T09:04:03+05:30", "updated_utc": "2024-06-23T03:34:03+00:00"}, {"path": "go_import-unused-package.md", "topic": "go", "title": "Import package without using it via underscore (`_`)", "url": "https://github.com/CuriousLearner/til/blob/main/go/import-unused-package.md", "body": "In Go, using `_` in imports allows you to import packages solely for their side effects, bypassing the Go compiler's `unused import error`. This is particularly useful when you need to execute code in the imported package's `init()` functions or register with a global state.\n\nExample:\n```go\npackage main\n\nimport _ \"github.com/some/package\" // Importing for side effects\n\nfunc main() {\n    // Your main program logic\n}\n```", "created": "2024-06-23T09:40:10+05:30", "created_utc": "2024-06-23T04:10:10+00:00", "updated": "2024-06-23T09:40:10+05:30", "updated_utc": "2024-06-23T04:10:10+00:00"}, {"path": "django_add-q-in-django-queryset.md", "topic": "django", "title": "Using `add_q` in Django Queries", "url": "https://github.com/CuriousLearner/til/blob/main/django/add-q-in-django-queryset.md", "body": "In Django, the `add_q` method is part of the internal QuerySet API and is used to combine complex query conditions using Q objects. It allows you to dynamically build and combine queries with logical operators.\n\n```python\nfrom django.db.models import Q\nfrom myapp.models import MyModel\n\n# Create an initial queryset\nqs = MyModel.objects.all()\n\n# Create Q objects for complex conditions\nq1 = Q(name__icontains='example')\nq2 = Q(age__gte=18) | Q(city='New York')\n\n# Use add_q to combine conditions\nqs.query.add_q(q1)\nqs.query.add_q(q2)\n\n# Evaluate the final queryset\nresults = qs.all()\n```\n\nThis will be an implicit `AND` between `q1` and `q2`, meaning it will return rows where both conditions are true. You can also explicitly use `Q.And` for an `AND` or `Q.Or` for an `OR`.", "created": "2024-06-23T09:36:21+05:30", "created_utc": "2024-06-23T04:06:21+00:00", "updated": "2024-06-23T09:36:21+05:30", "updated_utc": "2024-06-23T04:06:21+00:00"}, {"path": "django_generate-random-secrety-key.md", "topic": "django", "title": "Generate random secret key", "url": "https://github.com/CuriousLearner/til/blob/main/django/generate-random-secrety-key.md", "body": "```\nfrom django.core.management.utils import get_random_secret_key\n\nsecret_key = get_random_secret_key()\nprint(secret_key)\n```\n\nThis generates a random secret key like `5gga#kdyy9twdab)v@_p%koib6mc_1qmpe8b-=5nm4lf24m-s)`", "created": "2024-06-03T20:02:52+05:30", "created_utc": "2024-06-03T14:32:52+00:00", "updated": "2024-06-03T20:02:52+05:30", "updated_utc": "2024-06-03T14:32:52+00:00"}, {"path": "django_defer-fields-for-performance.md", "topic": "django", "title": "Use `defer()` to limit fields fetched from models", "url": "https://github.com/CuriousLearner/til/blob/main/django/defer-fields-for-performance.md", "body": "This is a use-case I came across in a project that uses PostGIS and manages lat/long as a `PointField`. If you retrieve this GIS data, when you don't need it, it has an expensive overhead of fetching all metadata of GIS. This can cause a serious bottleneck in your APIs.\n\nYou can use `defer` method to limit the fields fetched.\n\nFor example:\n\n```Python\nrestaurant_qs = Restaurant.objects.defer('point')\n```\n\nThis will fetch all the restaurants without the `point` field -- which means avoid loading all GIS data that isn't needed.\n\nA bit of warning though; if you end up accessing deferred field on any instance of queryset, it will make another trip to database to fetch that information.", "created": "2023-02-12T03:39:10+05:30", "created_utc": "2023-02-11T22:09:10+00:00", "updated": "2023-02-12T03:39:10+05:30", "updated_utc": "2023-02-11T22:09:10+00:00"}, {"path": "django_redundant-all-in-queryset.md", "topic": "django", "title": "Redundant all chaining in queryset", "url": "https://github.com/CuriousLearner/til/blob/main/django/redundant-all-in-queryset.md", "body": "The default queryset from manager includes all the objects already. So, in most cases, `.all()` call can be avoided while chaining querysets.\n\nFor example:\n\n```python\nPost.objects.all().filter(title__startswith='Cool post')\n```\n\ncan be trimmed down to:\n\n```python\nPost.objects.filter(title__startswith='Cool post')\n```\n\nThe only reason to chain from `.all()` is for `delete()`, as a safeguard to ensure you really mean to delete everything: `Post.objects.all().delete()`.", "created": "2023-02-12T03:07:11+05:30", "created_utc": "2023-02-11T21:37:11+00:00", "updated": "2023-02-12T03:07:11+05:30", "updated_utc": "2023-02-11T21:37:11+00:00"}, {"path": "django_empty-database.md", "topic": "django", "title": "Empty database", "url": "https://github.com/CuriousLearner/til/blob/main/django/empty-database.md", "body": "`python manage.py flush` to empty all tables in the database.\n\n`python manage.py reset_db` to drop the database schema. Particularly helpful when trying to restore a database dump.", "created": "2023-07-08T01:00:47+05:30", "created_utc": "2023-07-07T19:30:47+00:00", "updated": "2023-07-08T01:00:47+05:30", "updated_utc": "2023-07-07T19:30:47+00:00"}, {"path": "django_set-whole-queryset-in-m2m-relationship.md", "topic": "django", "title": "Add Multiple Objects In Queryset In Many To Many Relationship", "url": "https://github.com/CuriousLearner/til/blob/main/django/set-whole-queryset-in-m2m-relationship.md", "body": "In Django, to add multiple objects in a many-to-many relationship, use the `set()` method. This replaces current related objects with a new set.\n\nFor example, with models Ad and Newsletter having a many-to-many relationship via newsletter:\n\n```python\nnew_ad.newsletter.set(original_ad.newsletter.all())\n```\n\n**NOTE**: This sets new_ad's newsletters to be the same as original_ad's. No need for `.save()` after `.set()`.", "created": "2024-06-23T09:12:54+05:30", "created_utc": "2024-06-23T03:42:54+00:00", "updated": "2024-06-23T09:12:54+05:30", "updated_utc": "2024-06-23T03:42:54+00:00"}, {"path": "github-actions_ruff-github-comments.md", "topic": "github-actions", "title": "Enable automatic inline annotations in PR using Ruff", "url": "https://github.com/CuriousLearner/til/blob/main/github-actions/ruff-github-comments.md", "body": "To quickly see inline annotations from [ruff](https://github.com/charliermarsh/ruff) in your Github pull request, use `--format github` in Github Actions file like:\n\n```yaml\nname: CI\non: push\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Install Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.11\"\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install ruff\n      # Include `--format=github` to enable automatic inline annotations.\n      - name: Run Ruff\n        run: ruff check --format=github .\n```", "created": "2023-02-13T02:36:59+05:30", "created_utc": "2023-02-12T21:06:59+00:00", "updated": "2023-02-13T02:36:59+05:30", "updated_utc": "2023-02-12T21:06:59+00:00"}, {"path": "github-actions_push-to-repo.md", "topic": "github-actions", "title": "Permissions for pushing to a repository", "url": "https://github.com/CuriousLearner/til/blob/main/github-actions/push-to-repo.md", "body": "By default, the Github Action's bot has only read permission on the repository it is running the action on.\n\nIf you try to push to the repository through Github Actions' bot, [you'll get this error which I got on first build of my TIL repo](https://github.com/CuriousLearner/til/actions/runs/4153164170/jobs/7184624317): `remote: Permission to CuriousLearner/til.git denied to github-actions[bot].`\n\nUnder `Repository settings > Actions > General > Workflow permissions`, update permission scope to `Read and write permissions` which states `Workflows have read and write permissions in the repository for all scopes.`", "created": "2023-02-12T02:53:52+05:30", "created_utc": "2023-02-11T21:23:52+00:00", "updated": "2023-02-12T02:56:45+05:30", "updated_utc": "2023-02-11T21:26:45+00:00"}]